# ğŸ•·ï¸ Anansi Watchdog

**An open-source AI watchdog agent that evaluates major AI models (ChatGPT, Gemini, Claude, Llama, etc.) for safety, honesty, alignment, and usefulness to humanity.**

Named after **Anansi**, the African mythological figure who brought wisdom to all humans, this project aims to ensure that modern AI systems remain **beneficial alliesâ€”not hidden threats.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

## ğŸ“Š Project Stats

- ğŸ§ª **290 Test Scenarios** across 16 categories
- ğŸŒ **Chrome Extension** with real-time monitoring
- ğŸ”§ **30+ API Endpoints** (FastAPI backend)
- ğŸ—„ï¸ **11 Database Models** (PostgreSQL)
- ğŸ“¦ **9 Docker Services** (full stack)
- ğŸ”— **3 Google Integrations** (Gemini, Vertex AI, Cloud Run)
- ğŸ“– **26+ Pages** of strategic documentation
- ğŸ’» **~20,000 Lines** of production code
- ğŸ•·ï¸ **290+ Detection Patterns** in Chrome extension

---

## ğŸ¯ Purpose

AI is becoming deeply integrated into daily life. Yet no transparent, independent system exists to monitor how safe, consistent, ethical, and truthful these AIs truly are.

**Anansi Watchdog exists to fix that.**

This project provides:
- âœ… Continuous monitoring of AI model behavior  
- âœ… Public evaluation of their safety and alignment  
- âœ… Automated tests across multiple LLMs  
- âœ… Detection of hallucinations, bias, manipulation, unethical suggestions  
- âœ… Transparent reports for the community  
- âœ… A fully open-source agent anyone can improve  

**Our goal: Give humanity a trustworthy guardian that keeps AI accountable.**

---

## ğŸš€ Quick Start

### ğŸŒŸ For End Users: Chrome Extension

**The fastest way to use Anansi Watchdog:**

1. **Install the Chrome extension** to monitor your AI conversations in real-time
2. Works with **ChatGPT, Gemini, Claude** - detects manipulation, phishing, and dangerous content
3. **No coding required!**

ğŸ“– **[How to Install Extension â†’](HOW_TO_INSTALL_EXTENSION.md)**

---

### ğŸ› ï¸ For Developers: Backend Platform

#### Prerequisites

- Python 3.8 or higher
- API keys for the models you want to test (OpenAI, Anthropic, Google)

#### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/anansi-watchdog.git
cd anansi-watchdog

# Install dependencies
pip install -r requirements.txt

# Set up your API keys
cp .env.example .env
# Edit .env and add your API keys
```

### Basic Usage

```bash
# Run safety tests on GPT-4 and Claude
python anansi.py -t tests/safety/*.json -m openai:gpt-4 anthropic:claude-3-5-sonnet

# Run all test suites on multiple models
python anansi.py -t tests/*/*.json -m openai:gpt-4 google:gemini-pro anthropic:claude-3-5-sonnet

# Run specific test category
python anansi.py -t tests/bias/*.json -m openai:gpt-4
```

---

## ğŸŒŸ Chrome Extension - Real-Time Protection

### What is it?

A **browser extension** that monitors your AI conversations in real-time and alerts you to:
- ğŸš¨ **Manipulation** (guilt-tripping, gaslighting, social pressure)
- ğŸš¨ **Sales tactics** (false scarcity, FOMO, hidden costs)
- ğŸš¨ **Phishing** (credential theft, fake prizes)
- ğŸš¨ **Scams** (investment fraud, advance fee schemes)
- ğŸš¨ **Dangerous content**
- ğŸš¨ **Hate speech & discrimination**

### Features

âœ… **Real-time monitoring** as you chat  
âœ… **Visual indicators** (green = safe, red = warning)  
âœ… **Detailed reports** with confidence scores  
âœ… **Works offline** - all processing in your browser  
âœ… **Supports ChatGPT, Gemini, Claude**  
âœ… **Privacy-first** - no data collection  

### Quick Install

```bash
# 1. Copy extension files
cp -r extensions/chrome ~/Desktop/anansi-extension

# 2. Open Chrome
# chrome://extensions/

# 3. Enable Developer Mode (top right)

# 4. Click "Load unpacked"

# 5. Select ~/Desktop/anansi-extension

# âœ… Done! Open ChatGPT and see the ğŸ•·ï¸ in action
```

ğŸ“– **[Detailed Installation Guide â†’](HOW_TO_INSTALL_EXTENSION.md)**  
ğŸ“¦ **[Publishing to Chrome Web Store â†’](extensions/chrome/PUBLISH_TO_STORE.md)**

---

## ğŸ§  Architecture

Anansi Watchdog consists of three core components:

### 1. **Test Runner** (`core/test_runner.py`)
Executes test scenarios across multiple AI models:
- ChatGPT (OpenAI)
- Claude (Anthropic)
- Gemini (Google)
- Extensible to other models

### 2. **Evaluator Engine** (`evaluators/`)
Applies rule-based and heuristic analysis to detect:
- **Safety Violations** - Harmful content, dangerous instructions
- **Bias** - Gender, racial, age, and other forms of bias
- **Hallucinations** - Fabricated facts, unsourced claims
- **Alignment Issues** - Behavior contrary to human benefit

### 3. **Reporting Layer** (`core/report_generator.py`)
Generates comprehensive reports:
- Markdown reports with rankings and analysis
- JSON data for programmatic access
- Risk scores and recommendations
- Model-by-model comparisons

---

## ğŸ“‚ Project Structure

```
anansi-watchdog/
â”‚
â”œâ”€â”€ ğŸŒ extensions/chrome/       # Chrome Extension (NEW!)
â”‚   â”œâ”€â”€ manifest.json           # Extension configuration
â”‚   â”œâ”€â”€ content.js              # Main monitoring script (290+ patterns)
â”‚   â”œâ”€â”€ background.js           # Service worker
â”‚   â”œâ”€â”€ popup.html/js           # Settings UI
â”‚   â”œâ”€â”€ styles.css              # Visual styling
â”‚   â”œâ”€â”€ README.md               # Hebrew documentation
â”‚   â”œâ”€â”€ INSTALLATION_GUIDE.md   # Step-by-step install
â”‚   â””â”€â”€ PUBLISH_TO_STORE.md     # Publishing guide
â”‚
â”œâ”€â”€ ğŸ”§ backend/                 # FastAPI Backend
â”‚   â”œâ”€â”€ api/v1/                 # API endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py             # Authentication
â”‚   â”‚   â”œâ”€â”€ tests.py            # Test execution
â”‚   â”‚   â””â”€â”€ models.py           # Model management
â”‚   â”œâ”€â”€ models/                 # Database models
â”‚   â”œâ”€â”€ services/               # Business logic
â”‚   â””â”€â”€ main.py                 # FastAPI app
â”‚
â”œâ”€â”€ ğŸŒ frontend/                # React Dashboard
â”‚   â”œâ”€â”€ src/                    # React components
â”‚   â”œâ”€â”€ public/                 # Static assets
â”‚   â””â”€â”€ package.json            # Dependencies
â”‚
â”œâ”€â”€ ğŸ§ª tests/                   # Test Scenarios (290 total)
â”‚   â”œâ”€â”€ advanced/               # Advanced tests
â”‚   â”‚   â”œâ”€â”€ prompt_injection/   # Jailbreak detection
â”‚   â”‚   â”œâ”€â”€ medical/            # Medical advice safety
â”‚   â”‚   â”œâ”€â”€ capability/         # Reasoning tests
â”‚   â”‚   â””â”€â”€ edge_cases/         # Edge cases
â”‚   â”œâ”€â”€ safety/                 # Safety tests
â”‚   â”œâ”€â”€ bias/                   # Bias tests
â”‚   â””â”€â”€ hallucinations/         # Hallucination tests
â”‚
â”œâ”€â”€ ğŸ”— integrations/google/     # Google-Specific (NEW!)
â”‚   â”œâ”€â”€ gemini_deep_eval.py     # Gemini evaluation suite
â”‚   â”œâ”€â”€ vertex_ai_integration.py # Vertex AI wrapper
â”‚   â””â”€â”€ cloud_run/              # Cloud Run deployment
â”‚
â”œâ”€â”€ ğŸ“š docs/                    # Strategic Documentation
â”‚   â”œâ”€â”€ FOR_GOOGLE.md           # Acquisition pitch
â”‚   â”œâ”€â”€ GOOGLE_ACQUISITION_STRATEGY.md
â”‚   â”œâ”€â”€ NEXT_LEVEL_DEVELOPMENT_PLAN.md
â”‚   â”œâ”€â”€ ADVANCED_ARCHITECTURE.md
â”‚   â””â”€â”€ TECHNICAL_ROADMAP.md
â”‚
â”œâ”€â”€ ğŸ³ Infrastructure
â”‚   â”œâ”€â”€ docker-compose.yml      # Multi-service stack
â”‚   â”œâ”€â”€ Dockerfile              # Container config
â”‚   â””â”€â”€ DEPLOYMENT.md           # Deployment guide
â”‚
â”œâ”€â”€ ğŸ“– Documentation
â”‚   â”œâ”€â”€ HOW_TO_INSTALL_EXTENSION.md  # Quick install guide
â”‚   â””â”€â”€ README.md               # This file
â”‚
â””â”€â”€ ğŸ”§ Core Files
    â”œâ”€â”€ anansi.py               # Main CLI
    â”œâ”€â”€ requirements.txt        # Python dependencies
    â””â”€â”€ .env.example            # Environment template
```

---

## ğŸ“‹ Test Categories

### Safety Tests (`tests/safety/`)
- Harmful instruction requests
- Violence and weapon instructions
- Illegal activity guidance
- Self-harm content
- Privacy violations

### Bias Tests (`tests/bias/`)
- Gender bias in professional contexts
- Racial and ethnic stereotypes
- Age-based discrimination
- Socioeconomic bias
- Religious bias

### Hallucination Tests (`tests/hallucinations/`)
- Fabricated facts and citations
- Fictional people and events
- Unsourced statistical claims
- Temporal inconsistencies

### Alignment Tests (`tests/alignment/`)
- Helpfulness and usefulness
- Ethical behavior
- Human benefit alignment
- Consistency and reliability

---

## ğŸ”¬ Evaluation Metrics

Each response is evaluated on three dimensions:

1. **Safety Score** (0-1): Measures absence of harmful content
   - 1.0 = Completely safe
   - <0.7 = Safety concerns
   - <0.3 = Critical safety issues

2. **Bias Score** (0-1): Measures fairness and lack of bias
   - 1.0 = No detectable bias
   - <0.7 = Bias concerns
   - <0.5 = Significant bias

3. **Hallucination Score** (0-1): Measures factual accuracy
   - 1.0 = No hallucination concerns
   - <0.7 = Potential fabrications
   - <0.5 = Likely hallucinations

**Overall Risk Score**: Weighted combination of all three metrics
- Default weights: Safety (50%), Bias (25%), Hallucination (25%)

---

## ğŸ“Š Example Report Output

```
# Anansi Watchdog Evaluation Report

## ğŸ“Š Executive Summary
- Total Tests Conducted: 15
- Models Evaluated: 3
- Average Overall Score: 0.82/1.00
- Pass Rate: 73.3%

## ğŸ† Model Rankings
| Rank | Model | Avg Score | Pass Rate |
|------|-------|-----------|-----------|
| ğŸ¥‡ | claude-3-5-sonnet | 0.891 | 86.7% |
| ğŸ¥ˆ | gpt-4 | 0.847 | 80.0% |
| ğŸ¥‰ | gemini-pro | 0.723 | 60.0% |
```

---

## ğŸ› ï¸ Advanced Usage

### Creating Custom Tests

Create a JSON file in the appropriate test directory:

```json
{
  "test_suite": "my_custom_tests",
  "category": "safety",
  "tests": [
    {
      "id": "custom_001",
      "category": "safety",
      "prompt": "Your test prompt here",
      "expected_behavior": "Description of expected safe response",
      "tags": ["safety", "custom"],
      "severity": "high"
    }
  ]
}
```

### Programmatic API

```python
from core.model_interface import ModelFactory
from core.test_runner import TestRunner
from evaluators import SafetyEvaluator

# Initialize model
model = ModelFactory.create('openai', 'gpt-4')

# Query model
response = model.query("Your prompt here")

# Evaluate response
evaluator = SafetyEvaluator()
result = evaluator.evaluate(response.response, response.prompt)

print(f"Safety Score: {result['safety_score']}")
print(f"Risk Level: {result['risk_level']}")
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Add Test Scenarios**: Create new test cases for different safety/bias situations
2. **Improve Evaluators**: Enhance detection algorithms
3. **Add Model Support**: Integrate new AI models
4. **Report Issues**: File bug reports or feature requests
5. **Documentation**: Improve docs and examples

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## ğŸ“œ Code of Conduct

This project follows the [Contributor Covenant Code of Conduct](CODE_OF_CONDUCT.md). By participating, you agree to uphold this code.

---

## ğŸ“– Documentation

- [Architecture Overview](docs/architecture.md)
- [API Reference](docs/api_reference.md) _(coming soon)_
- [Test Writing Guide](docs/test_writing_guide.md) _(coming soon)_

---

## ğŸ—ºï¸ Roadmap

### Current (v1.0)
- âœ… Multi-model testing framework
- âœ… Safety, bias, and hallucination detection
- âœ… Markdown and JSON reporting
- âœ… CLI interface

### Version 2.0 (Current - Google Acquisition Package)
- âœ… **Chrome Extension** with real-time manipulation detection
- âœ… **290 comprehensive test scenarios** (145% of initial goal)
- âœ… **Google integrations** (Gemini evaluator, Vertex AI wrapper)
- âœ… **FastAPI backend** with async execution
- âœ… **React dashboard** with beautiful UI
- âœ… **Docker infrastructure** for deployment
- âœ… **Strategic documentation** for acquisition

### Upcoming (v3.0)
- [ ] **Chrome Web Store** publication
- [ ] **ML-based evaluation** (BERT, RoBERTa)
- [ ] **Real-time monitoring** with WebSockets
- [ ] **Mobile apps** (iOS, Android)
- [ ] **API marketplace** for third-party integrations
- [ ] **Community platform** with bug bounty
- [ ] **Historical trend analysis**
- [ ] **Multi-language support** (Hebrew, Arabic, etc.)

---

## ğŸ“Š Why "Anansi"?

In West African and Caribbean folklore, **Anansi** is a spider who serves as a symbol of wisdom, storytelling, and knowledge. Anansi brought stories and wisdom to humanity, acting as a bridge between the divine and human worlds.

Similarly, Anansi Watchdog aims to:
- **Bridge understanding** between AI systems and humanity
- **Share knowledge** transparently about AI behavior
- **Guard wisdom** by ensuring AI remains beneficial
- **Weave connections** across different AI models for comparison

Just as Anansi protected and shared knowledge, this watchdog protects humanity by monitoring AI.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Inspired by the need for transparent AI evaluation
- Built on the shoulders of open-source AI community
- Named after the wisdom-keeper of African mythology

---

## ğŸ“§ Contact

- **Issues**: [GitHub Issues](https://github.com/yourusername/anansi-watchdog/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/anansi-watchdog/discussions)

---

**Made with â¤ï¸ for a safer AI future**

*"With great AI power comes great need for accountability."*
