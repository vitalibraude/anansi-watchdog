Anansi Watchdog Project Structure
==================================

anansi-watchdog/
â”‚
â”œâ”€â”€ ğŸ“„ Core Files
â”‚   â”œâ”€â”€ README.md                    # Main project documentation
â”‚   â”œâ”€â”€ QUICKSTART.md                # Quick start guide
â”‚   â”œâ”€â”€ CONTRIBUTING.md              # Contribution guidelines
â”‚   â”œâ”€â”€ CODE_OF_CONDUCT.md           # Code of conduct
â”‚   â”œâ”€â”€ PROJECT_SUMMARY.md           # Complete project summary
â”‚   â”œâ”€â”€ LICENSE                      # MIT License
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ setup.sh                     # Automated setup script
â”‚   â”œâ”€â”€ .env.example                 # Environment template
â”‚   â””â”€â”€ anansi.py                    # Main CLI interface â­
â”‚
â”œâ”€â”€ ğŸ§  Core Framework (core/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_interface.py           # Multi-LLM interface (320 lines)
â”‚   â”œâ”€â”€ test_runner.py               # Test execution engine (280 lines)
â”‚   â””â”€â”€ report_generator.py          # Report generation (365 lines)
â”‚
â”œâ”€â”€ ğŸ” Evaluators (evaluators/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ safety_rules.py              # Safety evaluation (330 lines)
â”‚   â”œâ”€â”€ bias_detector.py             # Bias detection (380 lines)
â”‚   â”œâ”€â”€ hallucination_detector.py    # Hallucination detection (365 lines)
â”‚   â””â”€â”€ risk_score.py                # Risk scoring (325 lines)
â”‚
â”œâ”€â”€ ğŸ§ª Test Scenarios (tests/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ safety/
â”‚   â”‚   â””â”€â”€ harmful_instructions.json    # 5 safety tests
â”‚   â”œâ”€â”€ bias/
â”‚   â”‚   â””â”€â”€ gender_bias.json             # 5 bias tests
â”‚   â”œâ”€â”€ hallucinations/
â”‚   â”‚   â””â”€â”€ factual_claims.json          # 5 hallucination tests
â”‚   â””â”€â”€ alignment/
â”‚       â””â”€â”€ helpfulness.json             # 5 alignment tests
â”‚
â”œâ”€â”€ âš™ï¸ Configuration (config/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ config.py                    # Central configuration
â”‚
â”œâ”€â”€ ğŸ“š Documentation (docs/)
â”‚   â””â”€â”€ architecture.md              # Detailed architecture docs
â”‚
â”œâ”€â”€ ğŸ’¡ Examples (examples/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ simple_example.py            # Usage examples (250 lines)
â”‚
â””â”€â”€ ğŸ“Š Outputs (outputs/)            # Auto-generated
    â”œâ”€â”€ reports/                     # Markdown & JSON reports
    â”œâ”€â”€ logs/                        # Execution logs
    â””â”€â”€ data/                        # Raw test data


ğŸ“Š Project Statistics
=====================

Python Code:          2,505 lines
Test Scenarios:       20 test cases (4 categories)
Documentation:        5 comprehensive docs
Supported Models:     5+ models (3 providers)
Core Modules:         12 Python modules
Evaluation Dimensions: 3 (safety, bias, hallucination)


ğŸ¯ Key Features
===============

âœ… Multi-Model Support      - Test ChatGPT, Claude, Gemini, and more
âœ… Safety Evaluation        - Detect harmful content and violations
âœ… Bias Detection           - Identify gender, racial, age biases
âœ… Hallucination Detection  - Catch fabricated facts and claims
âœ… Risk Scoring             - Multi-dimensional weighted assessment
âœ… Comprehensive Reports    - Both Markdown and JSON formats
âœ… CLI Interface            - Easy command-line usage
âœ… Extensible Architecture  - Add models, tests, evaluators
âœ… Production Ready         - Error handling, logging, config
âœ… Well Documented          - README, guides, examples, architecture


ğŸš€ Quick Start Commands
=======================

Setup:
  ./setup.sh

Run Tests:
  python anansi.py -t tests/safety/*.json -m openai:gpt-4
  python anansi.py -t tests/*/*.json -m openai:gpt-4 anthropic:claude-3-5-sonnet

Examples:
  python examples/simple_example.py


ğŸ“– Documentation Files
======================

README.md           - Main project overview (9,449 chars)
QUICKSTART.md       - Quick start guide (4,856 chars)
CONTRIBUTING.md     - Contribution guidelines (6,337 chars)
CODE_OF_CONDUCT.md  - Community code of conduct (5,646 chars)
PROJECT_SUMMARY.md  - Complete project summary (8,159 chars)
architecture.md     - Technical architecture (8,733 chars)


ğŸ“ Innovation Highlights
========================

1. First open-source multi-model AI watchdog
2. Unified evaluation framework across providers
3. Transparent, rule-based evaluation
4. Community-contributable test scenarios
5. Comprehensive multi-dimensional assessment
6. Production-ready with CLI and examples


Made with â¤ï¸ for a safer AI future
